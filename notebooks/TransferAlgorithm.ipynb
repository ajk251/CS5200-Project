{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferAlgorithm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajk251/CS5200-Project/blob/main/notebooks/TransferAlgorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlK3WAM8wvdC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQM09Mn7wuJD"
      },
      "source": [
        "Start with importing TensorFlow and needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEECnlAIwiP7",
        "outputId": "b80ff581-13bf-4d3b-ce63-9f92e300174a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.random.seed(7)\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scytclJIwsyU"
      },
      "source": [
        "Starting with content and style images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-c-sL5Nw9D4",
        "outputId": "da8fb583-8e79-4971-f8af-755b2eca1b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "# Load the content and style images\n",
        "content = plt.imread('/content/drive/My Drive/CSE 5200 Project/content1.jpg')\n",
        "style = plt.imread('/content/drive/My Drive/CSE 5200 Project/style.jpg')\n",
        "\n",
        "# Display the images\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Content and style images side-by-side\n",
        "ax1.imshow(content)\n",
        "ax1.set_title('Content Image')\n",
        "ax2.imshow(style)\n",
        "ax2.set_title('Style Image')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-439f50e643b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the content and style images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CSE 5200 Project/content1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CSE 5200 Project/style.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Display the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1462\u001b[0m             raise ValueError('Only know how to handle PNG; with Pillow '\n\u001b[1;32m   1463\u001b[0m                              'installed, Matplotlib can handle more images')\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/CSE 5200 Project/content1.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYLrPrUszGsE"
      },
      "source": [
        "def load_image(image):\n",
        "  image = plt.imread(image)\n",
        "  img = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  img = tf.image.resize(img, [400, 400])\n",
        "  # Shape -> (batch_size, h, w, d)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img\n",
        "\n",
        "# Use load_image of content and style images\n",
        "content = load_image('/content/drive/My Drive/CSE 5200 Project/content1.jpg')\n",
        "style = load_image('/content/drive/My Drive/CSE 5200 Project/style.jpg')\n",
        "\n",
        "# Verify the shapes\n",
        "content.shape, style.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSaOxDaPzz61"
      },
      "source": [
        "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "vgg.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkmW71SMz7kz"
      },
      "source": [
        "# Print the layer names for convenience\n",
        "for layer in vgg.layers:\n",
        "  print(layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUSzgZ6A0CRk"
      },
      "source": [
        "# Content layer\n",
        "content_layers = ['block4_conv2']\n",
        "\n",
        "# Style layer\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1',\n",
        "                'block4_conv1',\n",
        "                'block5_conv1']\n",
        "\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1M-Mu-90Ish"
      },
      "source": [
        "def mini_model(layer_names, model):\n",
        "\n",
        "  outputs = [model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "  model = Model([vgg.input], outputs)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuB3r-Ez0Nfv"
      },
      "source": [
        "# Gram matrix\n",
        "def gram_matrix(tensor):\n",
        "  temp = tensor\n",
        "  temp = tf.squeeze(temp)\n",
        "  fun = tf.reshape(temp, [temp.shape[2], temp.shape[0]*temp.shape[1]])\n",
        "  result = tf.matmul(temp, temp, transpose_b=True)\n",
        "  gram = tf.expand_dims(result, axis=0)\n",
        "  return gram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_lY1ohC0Ukz"
      },
      "source": [
        "class Custom_Style_Model(tf.keras.models.Model):\n",
        "  def __init__(self, style_layers, content_layers):\n",
        "    super(Custom_Style_Model, self).__init__()\n",
        "    self.vgg =  mini_model(style_layers + content_layers, vgg)\n",
        "    self.style_layers = style_layers\n",
        "    self.content_layers = content_layers\n",
        "    self.num_style_layers = len(style_layers)\n",
        "    self.vgg.trainable = False\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Scale back the pixel values\n",
        "    inputs = inputs*255.0\n",
        "    # Preprocess them with respect to VGG19 stats\n",
        "    preprocessed_input = preprocess_input(inputs)\n",
        "    # Pass through the mini network\n",
        "    outputs = self.vgg(preprocessed_input)\n",
        "    # Segregate the style and content representations\n",
        "    style_outputs, content_outputs = (outputs[:self.num_style_layers],\n",
        "                                      outputs[self.num_style_layers:])\n",
        "\n",
        "    # Calculate the gram matrix for each layer\n",
        "    style_outputs = [gram_matrix(style_output)\n",
        "                     for style_output in style_outputs]\n",
        "\n",
        "    # Assign the content representation and gram matrix in\n",
        "    # a layer by layer fashion in dicts\n",
        "    content_dict = {content_name:value\n",
        "                    for content_name, value\n",
        "                    in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "    style_dict = {style_name:value\n",
        "                  for style_name, value\n",
        "                  in zip(self.style_layers, style_outputs)}\n",
        "\n",
        "    return {'content':content_dict, 'style':style_dict}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE6pOFhA0ZJl"
      },
      "source": [
        "# Note that the content and style images are loaded in\n",
        "# content and style variables respectively\n",
        "extractor = Custom_Style_Model(style_layers, content_layers)\n",
        "style_targets = extractor(style)['style']\n",
        "content_targets = extractor(content)['content']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdjuReH_0ezP"
      },
      "source": [
        "opt = tf.optimizers.Adam(learning_rate=0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXRp9NI40ikm"
      },
      "source": [
        "# Custom weights for style and content updates\n",
        "style_weight=100\n",
        "content_weight=10\n",
        "\n",
        "# Custom weights for different style layers\n",
        "style_weights = {'block1_conv1': 1.,\n",
        "                 'block2_conv1': 0.8,\n",
        "                 'block3_conv1': 0.5,\n",
        "                 'block4_conv1': 0.3,\n",
        "                 'block5_conv1': 0.1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsIT89Xt0nXk"
      },
      "source": [
        "# The loss function to optimize\n",
        "def total_loss(outputs):\n",
        "    style_outputs = outputs['style']\n",
        "    content_outputs = outputs['content']\n",
        "    style_loss = tf.add_n([style_weights[name]*tf.reduce_mean((style_outputs[name]-style_targets[name])**2)\n",
        "                           for name in style_outputs.keys()])\n",
        "    # Normalize\n",
        "    style_loss *= style_weight / num_style_layers\n",
        "\n",
        "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2)\n",
        "                             for name in content_outputs.keys()])\n",
        "    # Normalize\n",
        "    content_loss *= content_weight / num_content_layers\n",
        "    loss = style_loss + content_loss\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZCt_Tav0sh1"
      },
      "source": [
        "@tf.function()\n",
        "def train_step(image):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Extract the features\n",
        "    outputs = extractor(image)\n",
        "    # Calculate the loss\n",
        "    loss = total_loss(outputs)\n",
        "  # Determine the gradients of the loss function w.r.t the image pixels\n",
        "  grad = tape.gradient(loss, image)\n",
        "  # Update the pixels\n",
        "  opt.apply_gradients([(grad, image)])\n",
        "  # Clip the pixel values that fall outside the range of [0,1]\n",
        "  image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKYWvTI90w7w"
      },
      "source": [
        "target_image = tf.Variable(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jHjbtDi01Kw"
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoch = 10\n",
        "\n",
        "step = 0\n",
        "for n in range(epochs):\n",
        "  for m in range(steps_per_epoch):\n",
        "    step += 1\n",
        "    train_step(target_image)\n",
        "  plt.imshow(np.squeeze(target_image.read_value(), 0))\n",
        "  plt.title(\"Train step: {}\".format(step))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_pZ_t0kPk72"
      },
      "source": [
        ""
      ]
    }
  ]
}